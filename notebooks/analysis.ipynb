{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Transforming Citi Bike Data for Analysis \n",
    "## How is Citi Bike availability affected by various factors like time of day and weather?\n",
    "\n",
    "### Who:\n",
    "I am [Alhan Keser](https://blog.alhan.co/), a [10+ year specialist in Web Experimentation](https://www.linkedin.com/in/alhankeser/) (aka A/B Testing, Conversion Optimization), on my way to a Master's in Data Science.\n",
    "\n",
    "### What:\n",
    "This is an original analysis of Citi Bike station data from May-June 2019 to find out what affect the day of week, time of day, and weather (temperature, precipitation, etc...) have on the availability of bikes at station-,  neighborhood-, and borough-levels. \n",
    "\n",
    "### Why:\n",
    "- I wanted to push myself to extract and transform my own data. Skipping the entire ETL process and going straight into analysis is a luxury: it does not reflect reality. \n",
    "- Doing a time-series analysis is something that I wanted practice with. \n",
    "- I commute by bike every day (despite weather) so I have first-hand evidence that Citi Bike riders tend to shy away from biking in inclement weather. It will be interesting to visualize the differences here.   \n",
    "\n",
    "### How:\n",
    "- **Combined original data sources:**\n",
    "    - [Citi Bike Live Station Status](https://feeds.citibikenyc.com/stations/stations.json)\n",
    "    - [Dark Sky Weather API](https://darksky.net/dev/docs)\n",
    "    - [Google Geocoding API](https://developers.google.com/maps/documentation/geocoding/intro)\n",
    "- **Created cron jobs** to collect Citi Bike station statuses for all ~858 stations, every 3 minutes, for ~2 months.\n",
    "    - Total rows in final table: 5,800,274\n",
    "    - \"Why stop after 2 months,\" you ask? Because my server ran out of space while I was on vacation. Here's what that looks like: \n",
    "\n",
    "![My server crashed July 14](https://blog.alhan.co/storage/images/posts/2/web-server-crashed_2_1568434613_sm.jpg)\n",
    "- **Created a mini-ETL process** to transform data into the final output used below. \n",
    "    - Along the way, there were many errors, some of which I will resolve here.\n",
    "\n",
    "### Table of Contents\n",
    "- [Packages](#Packages)\n",
    "- [Extracting](#Extracting)\n",
    "    - [Stations-Raw](#Stations-Raw)\n",
    "    - [Stations-Flat](#Stations-Flat)\n",
    "    - [Geocoding](#Geocoding)\n",
    "    - [Weather](#Weather)\n",
    "    - [Cron Jobs](#Cron-Jobs)\n",
    "- [Transforming](#Transforming)\n",
    "    - [Availability by Station](#Availability-by-Station)\n",
    "    - [Predicted vs Observed Weather](#Predicted-vs-Observed-Weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "Importing a few packages that will help with describing, cleaning and visualizing things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting\n",
    "I started by find an interesting data source. In this case, I found the [Citi Bike Station Feed](https://feeds.citibikenyc.com/stations/stations.json) via the [NYC Open Data site](https://opendata.cityofnewyork.us/).\n",
    "\n",
    "The feed shows the latest statuses of ~858 Citi Bike stations. Below is a list of values per station and sample data for each. Any keys left blank are often blank in the data source as well, which I'll address in later steps. \n",
    "\n",
    "| key | sample value |\n",
    "|------------:|:---------|\n",
    "| `id`        | 285|\n",
    "| `stationName` |\"Broadway & E 14St\"|\n",
    "| `availableDocks` |20|\n",
    "| `totalDocks` |53|\n",
    "| `latitude`|40.73454567|\n",
    "| `longitude`   |-73.99074142|\n",
    "| `statusValue` |\"In Service\"|\n",
    "| `statusKey`   |1|\n",
    "| `availableBikes` |31|\n",
    "| `stAddress1`  |\"Broadway & E 14 St\"|\n",
    "| `stAddress2`  |\"\"|\n",
    "| `city`        |\"\"|\n",
    "| `postalCode`  |\"\"|\n",
    "| `location`    |\"\"|\n",
    "| `altitude`    |\"\"|\n",
    "| `testStation` |false|\n",
    "| `lastCommunicationTime` |\"2019-09-12 08:38:21 PM\"|\n",
    "| `landMark`    |\"\"|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations-Raw\n",
    "\n",
    "To have a back-up in case any of the subsequent steps went awry, I wanted to store the source data in the simplest way possible: a table `stations_raw` that stored the following: \n",
    "\n",
    "|column_name|data_type|sample value|\n",
    "|-----------|-----------|----------|\n",
    "|id         |int4|31419|\n",
    "|status     |json|{\"executionTime\": \"2019-06-22 01:53:41 PM\", \"s...|\n",
    "\n",
    "Once the table created, I needed a way to collect data. A quick solution -- for me -- was to create [a Laravel application](https://github.com/alhankeser/citibike-tracker/)  that [makes it easy create console commands](https://laravel.com/docs/5.8/artisan#writing-commands). In combination with [Laravel Forge](https://forge.laravel.com), it's easy to set up a cron job that triggers [the necessary command](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L49) at set intervals.\n",
    "\n",
    "Once the commands created, I set up a [cron job](#Cron-Jobs) that ran once every 3 minutes. This resulted in the collection of 41,325 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations-Flat\n",
    "As part of the same command that creates the [stations_raw](#Stations-Raw) table, I [flattened out the JSON](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L80) and created a table with a single row per 3-minute interval, per station. We'll call this table `stations_flat` (probably could have used a better naming convention throughout this project). \n",
    "\n",
    "Here is the structure of `stations_flat` and some sample data:\n",
    "\n",
    "|column_name|data_type|sample value|description|\n",
    "|-----------|---------|------------|-----------|\n",
    "|id         |int4     |10511778    |row id|\n",
    "|station_id |int4     |72          |unique id for each station|\n",
    "|available_bikes|int4 |4           |number of available bikes at the station|\n",
    "|available_docks|int4 |49          |number of available docks (places to park a bike) at the station|\n",
    "|station_status|text  |In Service  |whether the station is in or out of service|\n",
    "|last_communication_time|timestamp|2019-05-15 01:14:15|the last time the station sent back data|\n",
    "\n",
    "After just over 2 months of this, I ended up with **34,301,048 rows** in this table. Luckily, I took some steps to make the volume of data more manageable when analyzing outside of a high CPU/RAM environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations-Static\n",
    "As the name suggests, `stations_static` contains information about each station that doesn't change minute-to-minute. Since there was a likelihood that stations be added, removed, renamed, I inserted or updated on duplicate each time `stations_flat` was updated. \n",
    "\n",
    "|column_name|data_type|sample_value|description|\n",
    "|-----------|---------|------------|-----------|\n",
    "|id| int4|3119|unique `station_id` found throughout db|\n",
    "|name| text|Vernon Blvd & 50 Ave||\n",
    "|latitude |float8|40.74232744||\n",
    "|longitude |float8|-73.95411749||\n",
    "|status_key| int4|1||\n",
    "|postal_code| text|NULL||\n",
    "|st_address_1| text|Vernon Blvd & 50 Ave||\n",
    "|st_address_2| text|NULL||\n",
    "|total_docks| int4|45||\n",
    "|status| text|In Service||\n",
    "|altitude| text|NULL||\n",
    "|location| text|NULL||\n",
    "|land_mark| text|NULL||\n",
    "|city| text|NULL||\n",
    "|is_test_station| int4|0||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geocoding\n",
    "As can be seen from the `stations_static` table above, many of the location-related values are null. This was the case for all stations. I wanted to be able to group stations by neighborhood and zip. Also, I wanted to use zip to associate weather data to each station, without having to make separate requests for each station (to stay within the free tier of the [Dark Sky Weather API](https://darksky.net/dev/docs)). \n",
    "\n",
    "To geocode from lat/long for each station into human-readeable location info, I used the [Google Geocoding API](https://developers.google.com/maps/documentation/geocoding/intro). [See the command I used to create the below table](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L92)\n",
    "\n",
    "|column_name|data_type|sample value|description|\n",
    "|-----------|---------|------------|-----------|\n",
    "|id|int4|1||\n",
    "|station_id|int4|3119|unique station id|\n",
    "|zip|text|11101|zip code of station|\n",
    "|hood_1|text|LIC|neighborhood or the closest thing provided by Google|\n",
    "|hood_2|text|Hunters Point|another level of neighborhood|\n",
    "|borough|text|Queens||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather\n",
    "### `IN PROGRESS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cron Jobs\n",
    "I'm not going to spend a lot of time on discussing cron jobs, but here are the patterns I was using to run everything. There is probably a more optimal approach that I am not aware of. \n",
    "\n",
    "|Cron       |Command|\n",
    "|-----------|-------|\n",
    "|\\*/3 \\* \\* \\* \\* | get:docks && update:availability 0 && update:weather|\n",
    "|0 \\*/2 \\* \\* \\*  | get:weather 0|\n",
    "\n",
    "View the code behind each command:\n",
    "- `get:docks` [view](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L49)\n",
    "- `update:availability 0` [view](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L179)\n",
    "- `update:weather` [view](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L359)\n",
    "- `get:weather 0` [view](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L276)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Availability by Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted vs Observed Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Complexity\n",
    "https://gist.github.com/alhankeser/9fbaf67a8ce052de72f22ab1630cd91c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-Generate README.md:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook analysis.ipynb to markdown\n",
      "[NbConvertApp] Writing 8489 bytes to ../README.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --output-dir='..' --to markdown analysis.ipynb --output README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
