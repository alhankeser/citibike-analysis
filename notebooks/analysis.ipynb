{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Transforming Citi Bike Data for Analysis \n",
    "## How is Citi Bike availability affected by various factors like time of day and weather?\n",
    "\n",
    "### Who:\n",
    "I am [Alhan Keser](https://blog.alhan.co/), a [10+ year specialist in Web Experimentation](https://www.linkedin.com/in/alhankeser/) (aka A/B Testing, Conversion Optimization), on my way to a Master's in Data Science.\n",
    "\n",
    "### What:\n",
    "This is an original analysis of Citi Bike station data from May-June 2019 to find out what affect the day of week, time of day, and weather (temperature, precipitation, etc...) have on the availability of bikes at station-,  neighborhood-, and borough-levels. \n",
    "\n",
    "### Why:\n",
    "- I wanted to push myself to extract and transform my own data. Skipping the entire ETL process and going straight into analysis is a luxury: it does not reflect reality. \n",
    "- Doing a time-series analysis is something that I wanted practice with. \n",
    "- I commute by bike every day (despite weather) so I have first-hand evidence that Citi Bike riders tend to shy away from biking in inclement weather. It will be interesting to visualize the differences here.   \n",
    "\n",
    "### How:\n",
    "- **Combined original data sources:**\n",
    "    - [Citi Bike Live Station Status](https://feeds.citibikenyc.com/stations/stations.json)\n",
    "    - [Dark Sky Weather API](https://darksky.net/dev/docs)\n",
    "    - [Google Geocoding API](https://developers.google.com/maps/documentation/geocoding/intro)\n",
    "- **Created cron jobs** to collect Citi Bike station statuses for all ~858 stations, every 3 minutes, for ~2 months.\n",
    "    - Total rows in final table: 5,800,274\n",
    "    - \"Why stop after 2 months,\" you ask? Because my server ran out of space while I was on vacation. Oops! \n",
    "![My server crashed July 14](https://blog.alhan.co/storage/images/posts/2/web-server-crashed_2_1568434613_sm.jpg)\n",
    "- **Created a mini-ETL process** to transform data into the final output used below. \n",
    "    - Along the way, there were many errors, some of which I will resolve here.\n",
    "\n",
    "### Table of Contents\n",
    "- [Packages](#Packages)\n",
    "- [Extracting](#Extracting)\n",
    "    - [Stations-Raw](#Stations-Raw)\n",
    "    - [Stations-Flat](#Stations-Flat)\n",
    "    - [Geocoding](#Geocoding)\n",
    "    - [Weather](#Weather)\n",
    "    - [Cron Jobs](#Cron-Jobs)\n",
    "- [Transforming](#Transforming)\n",
    "    - [Availability by Station](#Availability-by-Station)\n",
    "    - [Predicted vs Observed Weather](#Predicted-vs-Observed-Weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "Importing a few packages that will help with describing, cleaning and visualizing things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting\n",
    "I started by find an interesting data source. In this case, I found the [Citi Bike Station Feed](https://feeds.citibikenyc.com/stations/stations.json) via the [NYC Open Data site](https://opendata.cityofnewyork.us/).\n",
    "\n",
    "The feed shows the latest statuses of ~858 Citi Bike stations. Below is a list of values per station and sample data for each. Any keys left blank are often blank in the data source as well, which I'll address in later steps. \n",
    "\n",
    "| key | sample value |\n",
    "|------------:|:---------|\n",
    "| `id`        | 285|\n",
    "| `stationName` |\"Broadway & E 14St\"|\n",
    "| `availableDocks` |20|\n",
    "| `totalDocks` |53|\n",
    "| `latitude`|40.73454567|\n",
    "| `longitude`   |-73.99074142|\n",
    "| `statusValue` |\"In Service\"|\n",
    "| `statusKey`   |1|\n",
    "| `availableBikes` |31|\n",
    "| `stAddress1`  |\"Broadway & E 14 St\"|\n",
    "| `stAddress2`  |\"\"|\n",
    "| `city`        |\"\"|\n",
    "| `postalCode`  |\"\"|\n",
    "| `location`    |\"\"|\n",
    "| `altitude`    |\"\"|\n",
    "| `testStation` |false|\n",
    "| `lastCommunicationTime` |\"2019-09-12 08:38:21 PM\"|\n",
    "| `landMark`    |\"\"|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations-Raw\n",
    "\n",
    "To have a back-up in case any of the subsequent steps went awry, I wanted to store the source data in the simplest way possible: I created a table `stations_raw` that stored the following: \n",
    "\n",
    "|column_name|data_type|\n",
    "|-----------:|:---------|\n",
    "|id        |int4|\n",
    "|created_at|timestamp|\n",
    "|status|json|\n",
    "\n",
    "Once the table created, I needed a way to collect data. A quick solution -- for me -- was to create [a Laravel application](https://github.com/alhankeser/citibike-tracker/)  that [makes it easy create console commands](https://laravel.com/docs/5.8/artisan#writing-commands). In combination with [Laravel Forge](https://forge.laravel.com), it's easy to set up a cron job that triggers [the necessary command](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L49) at set intervals.\n",
    "\n",
    "Once the commands created, I set up a [cron job](#Cron-Jobs) that ran once every 3 minutes. This resulted in the collection of 41,325 rows. Below I've provided a quick idea of what this base table looks like:\n",
    "\n",
    "|column_name|sample value|\n",
    "|----------:|:-----------|\n",
    "|id         |                                               31419|\n",
    "|status     |  {\"executionTime\": \"2019-06-22 01:53:41 PM\", \"s...|\n",
    "|created_at |                                 2019-06-22 13:54:01|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations-Flat\n",
    "As part of the same command that creates the [Stations-Raw](#Stations-Raw) table, I [flattened out the JSON](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L80) and created a table with a single row per 3-minute interval, per station. I called this table `docks` (probably could have used a better naming convention throughout this project). \n",
    "\n",
    "Here is the structure of `docks` and some sample data:\n",
    "\n",
    "|column_name|data_type|sample value|description|\n",
    "|-----------|---------|------------|-----------|\n",
    "|id         |int4     |10511778    |row id|\n",
    "|station_id |int4     |72          |unique id for each station|\n",
    "|available_bikes|int4 |4           |number of available bikes at the station|\n",
    "|available_docks|int4 |49          |number of available docks (places to park a bike) at the station|\n",
    "|station_status|text  |In Service  |whether the station is in or out of service|\n",
    "|last_communication_time|timestamp|2019-05-15 01:14:15|the last time the station sent back data|\n",
    "|created_at|timestamp|2019-05-15 01:15:02|when the row was created|\n",
    "\n",
    "After just over 2 months of this, I ended up with **34,301,048 rows** in this table. Luckily, I took some steps already to deal with the volume of data to make it manageable when analyzing outside of a high CPU/RAM environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cron Jobs\n",
    "I'm not going to spend a lot of time on discussing cron jobs, but here are the patterns I was using to run everything. There is probably a more optimal approach that I am not aware of. \n",
    "\n",
    "|Cron       |Command|\n",
    "|-----------|-------|\n",
    "|\\*/3 \\* \\* \\* \\* | get:docks && update:availability 0 && update:weather|\n",
    "|0 \\*/2 \\* \\* \\*  | get:weather 0|\n",
    "\n",
    "View the code behind each command:\n",
    "- `get:docks` [view](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L49)\n",
    "- `update:availability` [view](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L179)\n",
    "- `update:weather` [view](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L359)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Availability by Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted vs Observed Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto-Generate README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook analysis.ipynb to markdown\n",
      "[NbConvertApp] Writing 7493 bytes to ../README.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --output-dir='..' --to markdown analysis.ipynb --output README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
