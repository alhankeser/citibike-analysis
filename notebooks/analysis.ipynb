{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Transforming Citi Bike Data for Analysis \n",
    "## How is Citi Bike availability affected by various factors like time of day and weather?\n",
    "\n",
    "### Who:\n",
    "I am [Alhan Keser](https://blog.alhan.co/), a [10+ year specialist in Web Experimentation](https://www.linkedin.com/in/alhankeser/) (aka A/B Testing, Conversion Optimization), on my way to a Master's in Data Science.\n",
    "\n",
    "### What:\n",
    "This is an original analysis of Citi Bike station data from May-June 2019 to find out what affect the day of week, time of day, and weather (temperature, precipitation, etc...) have on the availability of bikes at station-,  neighborhood-, and borough-levels. \n",
    "\n",
    "### Why:\n",
    "- I wanted to push myself to extract and transform my own data. Skipping the entire ETL process and going straight into analysis is a luxury: it does not reflect reality. \n",
    "- Doing a time-series analysis is something that I wanted practice with. \n",
    "- I commute by bike every day (despite weather) so I have first-hand evidence that Citi Bike riders tend to shy away from biking in inclement weather. It will be interesting to visualize the differences here.   \n",
    "\n",
    "### How:\n",
    "- **Combined original data sources:**\n",
    "    - [Citi Bike Live Station Status](https://feeds.citibikenyc.com/stations/stations.json)\n",
    "    - [Dark Sky Weather API](https://darksky.net/dev/docs)\n",
    "    - [Google Geocoding API](https://developers.google.com/maps/documentation/geocoding/intro)\n",
    "- **Created cron jobs** to collect Citi Bike station statuses for all ~858 station, every 3 minutes, for ~2 months.\n",
    "    - Total rows in final table: 5,800,274\n",
    "    - \"Why stop after 2 months,\" you ask? Because my server ran out of space while I was on vacation. Oops! \n",
    "- **Created a mini-ETL process** to transform data into the final output used below. \n",
    "    - Along the way, there were many errors, some of which I will resolve here.\n",
    "\n",
    "### Table of Contents\n",
    "- [Packages](#Packages)\n",
    "- [Extracting](#Extracting)\n",
    "    - [Stations](#Stations)\n",
    "    - [Geocoding](#Geocoding)\n",
    "    - [Weather](#Weather)\n",
    "    - [Cron Jobs](#Cron-Jobs)\n",
    "- [Transforming](#Transforming)\n",
    "    - [Availability by Station](#Availability-by-Station)\n",
    "    - [Predicted vs Observed Weather](#Predicted-vs-Observed-Weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "Importing a few packages that will help with describing, cleaning and visualizing things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting\n",
    "I started by find an interesting data source. In this case, I found the [Citi Bike Station Feed](https://feeds.citibikenyc.com/stations/stations.json) via the [NYC Open Data site](https://opendata.cityofnewyork.us/).\n",
    "\n",
    "The feed shows the latest statuses of ~858 Citi Bike stations. Below is a list of values per station and sample data for each. Any keys left blank are often blank in the data source as well, which I'll address in later steps. \n",
    "\n",
    "| key | sample value |\n",
    "|:------------|:---------:|\n",
    "| `id`        | 285|\n",
    "| `stationName` |\"Broadway & E 14St\"|\n",
    "| `availableDocks` |20|\n",
    "| `totalDocks` |53|\n",
    "| `latitude`|40.73454567|\n",
    "| `longitude`   |-73.99074142|\n",
    "| `statusValue` |\"In Service\"|\n",
    "| `statusKey`   |1|\n",
    "| `availableBikes` |31|\n",
    "| `stAddress1`  |\"Broadway & E 14 St\"|\n",
    "| `stAddress2`  |\"\"|\n",
    "| `city`        |\"\"|\n",
    "| `postalCode`  |\"\"|\n",
    "| `location`    |\"\"|\n",
    "| `altitude`    |\"\"|\n",
    "| `testStation` |false|\n",
    "| `lastCommunicationTime` |\"2019-09-12 08:38:21 PM\"|\n",
    "| `landMark`    |\"\"|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations\n",
    "\n",
    "To capture the raw station data without any transformations, I created a simple table that stored the following: \n",
    "\n",
    "|column_name|data_type|\n",
    "|-----------|---------|\n",
    "|created_at|timestamp|\n",
    "|data|json|\n",
    "\n",
    "Once the table created, I needed a way to collect data. A quick solution -- for me -- was to create a [Laravel](https://laravel.com/) application that [makes it easy to run console commands](https://laravel.com/docs/5.8/artisan#writing-commands). In combination with [Laravel Forge](https://forge.laravel.com), it's easy to set up cron jobs that trigger the necessary commands at set intervals.\n",
    "\n",
    "**Resources**:\n",
    "- [See the Laravel application I created to query station data](https://github.com/alhankeser/citibike-tracker/). \n",
    "- [See the request that extracts data for the base table](https://github.com/alhankeser/citibike-tracker/blob/d61f82adde88c90430205785297abf9f3de07c4d/app/Console/Kernel.php#L49)\n",
    "\n",
    "Once the commands created, I set up a cron job that ran once every 3 minutes. This resulted in the collection of 41,325 rows. Below I've done a quick analysis of the base table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_raw = pd.read_csv(\"../input/stations_raw.csv\") # 16.49 GB output from base SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Sample Row---\n",
      "id                                                        31419\n",
      "data          {\"executionTime\": \"2019-06-22 01:53:41 PM\", \"s...\n",
      "created_at                                  2019-06-22 13:54:01\n",
      "Name: 31418, dtype: object\n",
      "\n",
      "---Info---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41325 entries, 0 to 41324\n",
      "Data columns (total 3 columns):\n",
      "id            41325 non-null int64\n",
      "data          41325 non-null object\n",
      "created_at    41325 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 968.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('---Sample Row---')\n",
    "print(stations_raw.iloc[random.randint(0,len(stations_raw))])\n",
    "print('\\n---Info---')\n",
    "print(stations_raw.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create pandas DataFrame with flat \"availability\" table. \n",
    "\"\"\"\n",
    "df = pd.read_csv(\"../input/availability_sep2_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5800274, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cron Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Availability by Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted vs Observed Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto-Generate README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook analysis.ipynb to markdown\n",
      "[NbConvertApp] Writing 5979 bytes to ../README.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --output-dir='..' --to markdown analysis.ipynb --output README.md"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
